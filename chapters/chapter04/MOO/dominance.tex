\subsection{Dominance method}

For the MOO, the multi-objective vector could be ordered using the partial order on multi-objective spaces\cite{zitzler2003performance}. This method could refer to the pareto front definition. 

%here to introduce $\epsilon$-dominance.
We start with some basic definition and notation. Let $u=(u_1,\dots,u_d)\in \Rd$ and $v=(v_1,\dots,v_d)\in\Rd$ 
be two objective vectors. We define that $u$ weakly dominates $v$, denoted by $u\succeq v$, precisely if $u_i\geqslant v_i$ for all $i\in [1,\dots,d]$ and $u$ dominates $v$, denoted by $u\succ v$, precisely if $u\succeq v$ and $v\nsucceq u$. We denote the set of all Boolean values by $\mathbb{B}$ and the set of all real numbers by $\mathbb{R}$ and investigate the maximization of functions fitting in the shape of $f: \mathbb{B}^n \rightarrow \mathbb{R}^d$. 
We call $f$ objective function, $\mathbb{B}^n$ decision space and $\mathbb{R}^d$ objective vectors.  Let $x\in \mathbb{B}^n$ and $y\in\mathbb{B}^n$ be two decision vectors. We are able to use the same manners of speaking and notations for decision vectors, since the definition 
$x\succeq y : \Leftrightarrow f(x)\succeq f(y)$ transfers the concept of dominance from the objective space to the decision space. 

The set $\mathscr{PF}(f) := \{u\in f(\mathbb{B}^n)|\forall v \in f(\mathbb{B}^n: v\nsucc u)\}$ is called the Pareto front of $f$  and the set $\mathscr{P}(f):= f^{-1}(\mathscr{PF}(f)) = \{x\in \mathbb{B}^n| \forall y \in \mathbb{B}^n: y\nsucc x \}$ Pareto set of $f$. 
The set $\{(x,f(x))|x\in\mathscr{P}(f)\}$ constitutes the canonical solution of an optimization problem of the considered kind. In the literature a set of the form $\{(x,f(x)|x\in X)\}$ with $X\subseteq \mathscr{P}(f)$ is also considered as a valid solution if $f(X) = \mathscr{PF}(f)$. 
This means that it is sufficient to determine for all non-dominated objective vectors $u\in \mathscr{PF}(f)$ at least one decision vector $x\in\mathbb{B}^n$ with $f(x)=u$.

\vspace{3ex}
\textbf{Global Simple Evolutionary Multi-objective Optimization (Global SEMO)} \cite{horoba2008benefits} can be considered as one of the simplest population-based Evolutionary Algorithms for multi-objective optimization problems and has been analyzed with respect to its run-time behavior on pseudo-Boolean functions\cite{brockhoff2007additional,giel2010effect} as well as classical combination optimization problems. Global SEMO maintains a population of variable size which serves as an archive for the discovered non-dominated individual which is drawn uniformly at random from the decision space. In each generation an individual $x$ is drawn uniformly at random from the current population $P$. An offspring $y$ is created by applying a mutation operator to $X$. We resort to the global to the global mutation operator which flips each bit of $x$ with probability $1/n$ throughout this paper. The offspring is added to the population if it is not dominated by any other individual of $P$. All individuals which are weakly dominated by $y$ are in turn deleted from the population. The last step ensures that the population stores for each discovered non-dominated objective vector $u$ just the most recently created decision vector $x$ with $f(x)=u$. (see in Appendix~\ref{algo:GSEMO})

For theoretical investigations, we count  the number of rounds until a desired goal has been achieved. The number of these rounds is called the runtime of the considered algorithm. The expected runtime refers to the expectation of this random variable. For exact optimization often the expected optimization time is considered which equals the expected number of iterations until a decision vector for each objective vector of $\mathscr{PF}(f)$ has been included into the population. We are mainly interested in approximations.

We are considering the following model to measure the quality of an approximation. Let $\epsilon\in\mathbb{R}^+$ be a positive real number. We define that an objective vector $u$ $\epsilon$-dominates $v$, denoted by $u\succeq_\epsilon v$, precisely if $(1+\epsilon)\cdot u_i \geqslant v_i$ for all $i\in [1,\dots,m]$. We call a set $\mathscr{PF}_{\epsilon}(f) \subseteq f(\mathbb{B}^n)$ an $\epsilon$-approximate Pareto front of $f$ if 
\[\forall u\in f(\mathbb{B}^n): \exists v\in \mathscr{PF}_{\epsilon}(F): v\succeq_{\epsilon} u,\]
and a set $\mathscr{PF}^{\ast}_{\epsilon}(f) \subseteq \mathscr{PF}(f)$ an $\epsilon$-Pareto front of $f$ if $\mathscr{PF}^{\ast}_{\epsilon}(f)$ is an $\epsilon$-approximate Pareto front. The corresponding Pareto sets are naturally defined, i.e., $\mathscr{P}_{\epsilon}(f) := f^{-1}(\mathscr{PF}_{\epsilon}(f))$ and $\mathscr{P}^{\ast}_{\epsilon}(f) := f^{-1}(\mathscr{PF}^{\ast}_{\epsilon}(f))$. We point out that it is possible that there are several different $\epsilon$-approximate Pareto fronts or $\epsilon$-Pareto fronts for a given objective function. We also emphasize that $\epsilon$-Pareto fronts are of more value than $\epsilon$-approximate Pareto fronts to a decision maker, since all objective vectors of an $\epsilon$-Pareto front are non-dominated with respect to the classical concept of dominance. In the following parts, we limit our considerations to functions where the Pareto set contains all decision vectors and therefore the distinction between $\epsilon$-approximate Pareto fronts and $\epsilon$-Pareto fronts collapses.

\vspace{3ex}
\textbf{Global Diversity Evolutionary Multi-objective Optimizer (Global DEMO$_{\epsilon}$)} (shown in Appendix~\ref{algo:GDEMO}) incorporates the concept of $\epsilon$-dominance \cite{horoba2008benefits}. The idea is to partition the objective space into boxes such that all objective vectors in a box $\epsilon$-dominate each other. The algorithm maintains at each time step at most one individual per box. This approach ensures that the individuals contained in the population show some kind of diversity with respect to their objective vectors and that the size of the population can be controlled in a better way. These properties seem to be very important if we intend to approximate a large Pareto front. We formalize this idea by introducing the so-called box index vector which maps each decision vector to the index of its box. We assume a positive and normalized objective space, i.e., $f_i(x) \geqslant 1, \forall i \in [1,\cdots,m]$ and $x \in \mathbb{B}^n$. Let
\[b_i(x):=\left\lfloor \frac{\log{(f_i(x))}}{\log{(1+\epsilon)}}\right\rfloor\]
and denote by $b(x):= (b_1(x),\dots,b_m(x))$ the box index vector of a decision vector $x$. Global DEMO$_{\epsilon}$ works as Global SEMO with the exceptions that it does not accept an offspring with a dominated box index vector and that it deletes all individuals from the population whose box index vectors are weakly dominated by the box index vector of the offspring. This approach ensures that at most one individual per non-dominated box resides in the population.
