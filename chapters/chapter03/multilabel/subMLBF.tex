\subsection{Some multi-label algorithms working in Bandit setting}
\label{subsec:multilabelBF}
There are so many literature to introduce the multilabel classification \cite{madjarov2012extensive,gao2013consistency,kong2011ensemble,sorower2010literature}. Such problems are collectively referred to as learning with full information. As opposed to the full information case, in this section, we consider the multilabel classification follows the bandit setting. Firstly, it should construct a model for this setting. At $t$ time the side information vector $\xt\in \mathbb{R}^d$, is allowed to output at a subset $\hY\subseteq [K]$ of the set of possible labels, then the subset of labels $Y_t\subseteq [K]$ associated with $\xt$ is generated, and get a bandit feedback $\hY \cap Y_t$. 

\vspace{3ex}
\textbf{The algorithm based on 2nd-order descent in Bandit feedback} 
Here address the algorithm based on 2nd-order descent method, which is proposed by Gentile\cite{gentile2014multilabel}. It uses a linear predictor with a cost-sensitive multilabel loss that generalized the standard Hamming loss. In such setting, it is proven that the cumulative regret is bounded by $T^{1/2}\log{T}$. The loss suffered by the algorithm may take into account several things: the distance between $Y_t$ and $\hY$, as well as the cost for playing $\hY$. The cost $c(\hY)$ associated with $\hY$ might be given by the sum of costs suffered on each class $i\in \hY$, where we possibly take into account the order in which $i$ occurs within $\hY$. Specifically, given constant $a\in [0,1]$ and costs $c= \{c(i,s),i = 1,\dots,s, s\in[K]\}$, such that $1\geqslant c(1,s)\geqslant c(2,s)\geqslant\dots\geqslant c(s,s)\geqslant 0$, for all $s\in[K]$, this algorithm considers the loss function like below:
\[l_{a,c}(Y_t,\hY) = a|Y_t\setminus\hY| + (1-a)\sum_{i\in\hY\setminus Y_t}c(j_i,|\hY|)\],
where $j_i$ is the position of class $i$ in $\hY$, and $c(i_i,\cdot)$ depends on $\hY$ only through its size $|\hY|$. 
\iffalse
In the above, the first term accounts for the false negative mistakes, hence there is no specific ordering of labels therein. The second term collects the loss contribution provided by all false positive classes, taking into account through the costs $c(j_i,|\hY|)$ the order in which labels occur in $\hY$. The constant $a$ serves as weighting the relative importance of false positive vs. false negative mistakes. As a specific example, suppose that $K=10$, the cost $c(j,s)$ are given by $c(i,s) = (s-i+1)/s$, $i=1,\dots,s$, the algorithm plays $\hY = (5,2,7)$, but $Y_t$ is $(1,2,8)$. In this case, $|Y_t\setminus\hY| = 2$, and $\sum_{i\in\hY\setminus Y_t}c(j_i,|\hY|) = 3/3 + 1/3$, i.e. the cost for mistakingly playing class $5$ in the top slot of $\hY$ is more damaging than mistaking playing class $7$ in the third slot. In the special case when all costs are unitary, there is no longer need to view $\hY$ as an ordered collection, and the above loss reduces to a standard Hamming-like loss between sets $Y_t$ and $\hY$, i.e. $a|Y_t\setminus \hY|+(1-a)|\hY\setminus Y_t|$. Notice that the bandit feedback $\hY\cap Y_t$ allows the algorithm to know which of the chosen classes in $\hY$ are good or bad. Yet, the loss of $\loss_{a,c}(Y_t,\hY)$ because of hidden part of $Y_t\setminus\hY$. \fi

Working with the above loss function makes the algorithm's output $\hY$ become a ranked list of classes, where ranking is restricted to the deemed relevant classes only. In our setting, only a relevance feedback among the selected classes is observed (the set $Y_t\cap\hY$), but no supervised ranking information is provided to the algorithm within this set. Alternatively, we can think of a ranking framework where restrictions on the size of $\hY$ are set by an exogenous parameter of the problem, and the algorithm is required to provide a ranking complying with these restrictions.

\iffalse
For any subset $Y_t\subseteq[K]$, we let $(y_{1,t},\dots,y_{K,t})\in \{0,1\}^K$ be the corresponding indicator vector. Then it is easy to see that $\loss_{a,c}(Y_t,\hY) = a\sum_{i=1}^{K} y_{i,t} + (1-a)\sum_{i\in \hY}-(\frac{a}{1-a}+c(j_i,|\hY|)y_{i,t})$. Moreover, because the first sum does not depend on $\hY$, for the sake of optimizing over $\hY$ we can equivalently define
\begin{equation}
\label{equa:gentileML1}
\loss_{a,c}(Y_t,\hY) = (1-a)\underset{i\in\hY}{\sum}\left(c(j_i,|\hY|)-(\frac{a}{1-a}+c(j_i,|\hY|))y_{i,t}\right)
\end{equation}
\fi
Let $\mathbb{P}_t(\cdot)$ be a shorthand for the conditional probability $\mathbb{P}_t(\cdot|\xt)$, where the side information vector $\xt$ can in principle be generated by an adaptive adversary as a function of the past. Then $\mathbb{P}_t(y_{1,t},\dots,y_{K,t}) = \mathbb{P}(y_{1,t},\dots,y_{K,t}|\xt)$, where the marginals $\mathbb{P}_t(y_{i,t}=1)$satisfy 
\begin{equation}
\label{equa:gentileML2}
\mathbb{P}_t(y_{i,t} = 1) = \frac{g(-\mathbf{u}_i^T\xt)}{g(\mathbf{u}_i^T\xt)+g(-\mathbf{u}_i^T\xt)}, i=1,\dots,K
\end{equation}
for some $K$ vectors $\mathbf{u}_1,\dots,\mathbf{u}_K\in\mathbb{R}^d$ and some function $g: D\subseteq \mathbb{R}\rightarrow \mathbb{R}^+$. The model is well defined if $\mathbf{u}_i^T\xt \in D$ for all $i$ and all $\xt\in\mathbb{R}^d$ chosen by the adversary. We assume for the sake of simplicity that $\parallel{\xt}\parallel = 1$ for all $t$. Notice that at this point the variables $y_{i,t}$ need not be conditionally independent. We are only defining a family of allowed joint distributions $\mathbb{P}_t(y_{1,t},\dots,y_{K,t})$ through the properties of their marginals $\mathbb{P}_t(y_{i,t})$. 

The algorithm in Appendix~\ref{algo:MLBgentile}, here the unknown model vectors $u_1,\dots, u_K$ with prototype vectors $w_{1,t}',\dots,w_{K,t}'$, being $w_{i,t}'$ the time $t$ approximation to $u_i$, satisfying similar constraints we set for the $\mathbb{u}_i$ vectors. For the sake of brevity, we let $\hat{\Delta}_{i,t}' = \xt^Tw_{i,t}'$, and $\Delta_{i,t} = u_i^T\xt, i \in [K]$. The algorithm uses $\hat{\Delta}_{i,t}'$  as proxies for the underlying $\Delta_{i,t}$ according to the upper confidence approximation scheme $\Delta_{i,t}\approx [\hat{\Delta}_{i,t}'+\epsilon_{i,t}]_D$, where $\epsilon_{i,t}\geqslant 0$ is a suitable upper confidence level for class $i$ at time $t$. The algorithm's prediction $\hY$ at time $t$ has the same form as the computation of the Bayes optimal sequence $Y_t^{\ast}$ where we replace the $g(-\Delta_{i,t})$ of $p_{i,t}$ by $g([\hat{\Delta}_{i,t}'+\epsilon_{i,t}]_D)$.The algorithm receives in input the loss parameters $a$ and $c(i,s)$, the model function $g(\cdot)$ and the associated margin domain $D=[-R,+R]$, and maintains both $K$ weight vector $w_{i,t}\in \mathbb{R}^d$. At each time step $t$, upon receiving the $d$-dimensional instance vector $\xt$ the algorithm uses the weight vectors $w_{i,t}$ to compute the prediction vectors. These vectors can easily be seen as the result of projecting $w_{i,t}$ onto the space of $w$ where $|w^T\xt|\leqslant R$,  the distance function $d_{i,t-1}$, i.e. $w_{i,t}' = \text{arg min}_{w\in \mathbb{R}^d: w^T\xt\in D}d_{i,t-1}(w,w_{i,t}), i\in [K]$, where $d_{i,t}(u,w) = (u-w)^TA_{i,t}(u-w)$. Vectors $w_{i,t}'$ are then used to produce prediction values $\hat{\Delta}_{i,t}'$ involved in the upper confidence calculation of $\hY \subseteq [K]$. Next, the feedback $Y_t\cap \hY$ is observed, and the algorithm in Appendix~\ref{algo:MLBgentile} promotes all classes $i\in Y_t\cap\hY$, denotes all classes $i\in \hY\setminus Y_t$(sign $s_{i,t}=-1$), and leaves all remaining classes $i\neq\hY$ unchanged (sign $s_{i,t}=0$).  The update $w_{i,t}' \rightarrow w_{i,t+1}$ is based on the gradients $\triangledown_{i,t}$ of a loss function $L(\cdot)$ satisfying $L'(\Delta) = -g(\Delta)$. On the other hand, the update $A_{i,t-1} = A_{i,t}$ uses the rank one matrix $\xt\xt^T$. In both the update of $w_{i,t}'$ and the one involving $A_{i,t-1}$, the reader should observe the role played by the signs $s_{i,t}$. 

\iffalse
\begin{theo}
\label{theo:MLBgentil}
Let $L:D = [-R,R]\subseteq \mathbb{R} \rightarrow \mathbb{R}^+$ be a $C^2(D)$ convex and non-increasing function of its argument, $(u_1,\dots,u_K)\in \mathbb{R}^{dK}$ be defined in Equation~\ref{equa:gentileML2} with $g(\Delta) = -L'(\Delta)$ for all $\Delta\in D$, and such that $\parallel{u_i}\parallel\leqslant U$ for all $i\in[K]$. Assume there are positive constants $c_L,c_L'$ and $c_L''$ such that: $\frac{L'(\Delta)L''(-\Delta)+L''(\Delta)L'(-\Delta)}{(L'(\Delta)+L'(-\Delta))^2}\geqslant -c_L$ and $(L'(\Delta))^2\leqslant c_L'$, $L''(\Delta)\geqslant c_L''$ hold for all $\Delta\in D$. Then the cumulative regret $R_T$ of the algorithm in Algorithm~\ref{algo:MLBgentile} satisfies, with probability at least $1-\delta$,
\[R_T = O\left((1-a)c_LK\sqrt{TCd\ln{1+\frac{T}{d}}}\right)\], where $C = O\left(U^2+\frac{dc'_L}{(c_L'')^2}\ln{1+\frac{T}{d}}+(\frac{c_L'}{(c_L'')^2}+\frac{L(-R)}{c_L''})\ln{\frac{KT}{\delta}}\right)$
\end{theo}.
\fi